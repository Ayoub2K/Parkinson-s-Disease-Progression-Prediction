{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinson's disease progression notebook\n",
    "\n",
    "### Motivatie en originaliteit van de gebruikte methoden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het voorspellen van het verloop van de ziekte van Parkinson (PD) op basis van eiwitten uit onze gegeven is een complexe taak die een doordachte aanpak vereist. Hier zijn de stappen en overwegingen die wij hebben doorlopen voor het kiezen van het juiste model.\n",
    "\n",
    "#### Data Preprocessing:\n",
    "\n",
    "Wij zijn begonnen met het opgschonenen en voorbereiden van onze data, Hierbij hebben wij processen gebruikte als groeperen, piviton en mergen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(train_proteins: pd.DataFrame, train_peptides: pd.DataFrame):\n",
    "\n",
    "    # Grouping \n",
    "    df_protein_grouped = train_proteins.groupby([\"visit_id\",\"UniProt\"])[\"NPX\"].mean().reset_index()\n",
    "    df_peptide_grouped = train_peptides.groupby([\"visit_id\",\"Peptide\"])[\"PeptideAbundance\"].mean().reset_index()\n",
    "\n",
    "    # Pivoting\n",
    "    df_protein = df_protein_grouped.pivot(index=\"visit_id\", columns=\"UniProt\", values=\"NPX\").rename_axis(columns=None).reset_index()\n",
    "    df_peptide = df_peptide_grouped.pivot(index=\"visit_id\", columns=\"Peptide\", values=\"PeptideAbundance\").rename_axis(columns=None).reset_index()\n",
    "    \n",
    "    # Merging\n",
    "    pro_pep_df = df_protein.merge(df_peptide, on=[\"visit_id\"], how=\"left\")\n",
    "    \n",
    "    return pro_pep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection:\n",
    "\n",
    "Wij hebben ervoor gekozen om alle features te gebruiken die mogelijk zijn, dit omdat wij niet veel verschil konden vinden tussen features, dus het weghouden van bepaalde features zou in dat geval ononderbouwd zijn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection:\n",
    "\n",
    "Wij hebben ervoor gekozen om zowel met een Random Forest als Neural Network onze target te predicten, hieronder onze argumentatie waarom deze modellen goed bij onze doel past.\n",
    "\n",
    "#### Random Forests:\n",
    "\n",
    "- Random Forests is een leermethode die meerdere beslissingsbomen combineert om voorspellende nauwkeurigheid te verbeteren en overfitting te beheersen. het kan goed omgaan met data met veel dimensies, waardoor het geschikt is voor datasets met een groot aantal kenmerken van in dit geval eiwitten en petide waardes.\n",
    "- Robust tegen overfitting, outliers, noise,  and missende waardes.\n",
    "- kan niet-lineaire relaties in de gegevens vastleggen, waardoor het geschikt is in scenario's waarin de relatie tussen de waarden van de eiwiten en de ziekteprogressie non linear is.\n",
    "\n",
    "#### Neural Network:\n",
    "\n",
    "- Goed voor het vastleggen van complexe patronen, vooral in grote datasets.\n",
    "- Neurale netwerken kunnen automatisch relevante kenmerken uit de data halen, die wij met onze huidige domein kennis niet zouden herkennen.\n",
    "- Ze zijn flexibel en kunnen worden aangepast aan verschillende soorten gegevens en probleemscenario's. dit zal ons voornamelijk helpen omdat wij met dit probleem meerdere targets hebben.\n",
    "\n",
    "\n",
    "#### Training models:\n",
    "\n",
    "Wij hebben ervoor gekozen 20/80 training split te gebruiken voor beide modellen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = tfdf.keras.RandomForestModel(task=tfdf.keras.Task.REGRESSION, verbose=0)\n",
    "rf.compile(metrics=[\"mse\"])\n",
    "\n",
    "rf.fit(x=train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Random Forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = rf.make_inspector()\n",
    "inspector.evaluation()\n",
    "evaluation = rf.evaluate(x=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Het Resultaat van dit model:\n",
    "\n",
    "- Updrs 1 mse: 19.5633\n",
    "- Updrs 2 mse: 27.9235\n",
    "- Updrs 3 mse: 191.5821\n",
    "- Updrs 4 mse: 7.7804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hidden layers and output layers\n",
    "model = Sequential(\n",
    "[\n",
    "    layers.Dense(64, activation=\"tanh\", name=\"layer1\"),   \n",
    "    layers.Dense(64, activation=\"tanh\", name=\"layer2\"),   \n",
    "    layers.Dense(64, activation=\"tanh\", name=\"layer3\"),   \n",
    "    layers.Dense(64, activation=\"tanh\", name=\"layer4\"),   \n",
    "    layers.Dense(1),\n",
    "])\n",
    "    \n",
    "# Compile model to set optimizer, loss function and metrics\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(),\n",
    "    loss=losses.MeanSquaredError().name,\n",
    "    metrics=[losses.MeanSquaredError().name])\n",
    "\n",
    "# Fit The model\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=10, \n",
    "    validation_data=(x_test, y_test)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance in MeanSquaredError\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Het Resultaat van dit model:\n",
    "\n",
    "- Updrs 1 mse: 26.8737\n",
    "- Updrs 2 mse: 33.0623\n",
    "- Updrs 3 mse: 237.4834\n",
    "- Updrs 4 mse: 8.4585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Score\n",
    "\n",
    "Wij hebben er ook ervoor gekozen om de kaggle scores te vergelijken:\n",
    "\n",
    "#### Neural network:\n",
    "- Updrs 1 smape: 65.982\n",
    "- Updrs 2 smape: 87.542\n",
    "- Updrs 3 smape: 96.292\n",
    "- Updrs 4 smape: 148.666\n",
    "\n",
    "#### Random Forest:\n",
    "- Updrs 1 smape: 65.982\n",
    "- Updrs 2 smape: 87.542\n",
    "- Updrs 3 smape: 96.292\n",
    "- Updrs 4 smape: 148.666\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bevindingen\n",
    "\n",
    "Door zowel de Mean Square Errror als kaggle's Symmetric mean absolute percentage error score te vergelijken hebben wij concluderen dat de Random forest model beter resultaat levert voor ons probleem. \n",
    "\n",
    "Uit dit project is gebleken dat alhoewel de Neural network een goede model is hiervoor dat de random forest zowel consistenter als betere voorspellingen gaf. Hierom hebben wij gekozen om dit model in te leveren ondanks dat wij beide modellen uitvoerig getest hebben."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
